global:
    - add support for planar arrays
    - add benchmarks
    - compare speed with CUFFT + transpose
    - check all TODO's in code
    - check work for big arrays and batch sizes (and for array size == 1 maybe, just in case)
    - check work for both in-place and out-of-place transform
    - switch to templating engine
    - dynamically calculate proper block and grid size (so that their size is supported by GPU
      along with number of registers/shared mem/local mem). Do not forget to replace
      blockIdx.x by gridDim.x * blockIdx.y + blockIdx.x
    - when function uses too much registers, recreate with new block size only it, not the whole code
    - find a way to disable compilation warnings; probably can be done after moving to templating engine

optimizations (only after benchmarks!):
    - replace mad24() with vector function
    - replace cos() and sin() by faster analogues (if any) - see native_cos() in OpenCL
    - replace indexes with pointer arithmetic if someone answers in thread
    - for some reason compiler adds a[] arrays to shared memory (making kInfo.lmem_size incorrect)
      check if the generation code can be changed to make compiler put a[] in registers
    - some kernels have non-zero local memory size - probably they have to be recompiled in this case
      (or maybe it is just PyCuda showing incorrect size)
